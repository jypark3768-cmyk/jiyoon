import io
import unicodedata
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from plotly.subplots import make_subplots


# -----------------------------
# Page / Font
# -----------------------------
st.set_page_config(page_title="ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬", layout="wide")

st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', 'Malgun Gothic', sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)

PLOTLY_FONT_FAMILY = "Malgun Gothic, Apple SD Gothic Neo, sans-serif"


# -----------------------------
# Constants (í•™êµ/EC ì¡°ê±´ì€ ì—°êµ¬ ì„¤ê³„ê°’ì´ë¯€ë¡œ ìƒìˆ˜ë¡œ ë‘¡ë‹ˆë‹¤)
# íŒŒì¼ëª…/ì‹œíŠ¸ëª… í•˜ë“œì½”ë”©ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
# -----------------------------
EC_TARGET_BY_SCHOOL: Dict[str, float] = {
    "ì†¡ë„ê³ ": 1.0,
    "í•˜ëŠ˜ê³ ": 2.0,  # (ìµœì  í›„ë³´)
    "ì•„ë¼ê³ ": 4.0,
    "ë™ì‚°ê³ ": 8.0,
}

SCHOOL_COLOR: Dict[str, str] = {
    "ì†¡ë„ê³ ": "Blue",
    "í•˜ëŠ˜ê³ ": "Green",
    "ì•„ë¼ê³ ": "Orange",
    "ë™ì‚°ê³ ": "Red",
}

ENV_REQUIRED_COLS = ["time", "temperature", "humidity", "ph", "ec"]


# -----------------------------
# Unicode-safe helpers (NFC/NFD)
# -----------------------------
def _norm_variants(text: str) -> Tuple[str, str]:
    """Return (NFC, NFD) variants."""
    return (unicodedata.normalize("NFC", text), unicodedata.normalize("NFD", text))


def _norm_eq(a: str, b: str) -> bool:
    """Bidirectional NFC/NFD equivalence check."""
    a_nfc, a_nfd = _norm_variants(a)
    b_nfc, b_nfd = _norm_variants(b)
    return (a_nfc == b_nfc) or (a_nfc == b_nfd) or (a_nfd == b_nfc) or (a_nfd == b_nfd)


def _contains_norm(haystack: str, needle: str) -> bool:
    """NFC/NFD bidirectional substring check."""
    h_nfc, h_nfd = _norm_variants(haystack)
    n_nfc, n_nfd = _norm_variants(needle)
    return (n_nfc in h_nfc) or (n_nfd in h_nfc) or (n_nfc in h_nfd) or (n_nfd in h_nfd)


def _lookup_by_norm_key(mapping: Dict[str, float], key: str) -> Optional[float]:
    for k, v in mapping.items():
        if _norm_eq(k, key):
            return v
    return None


# -----------------------------
# File discovery (NO glob-only, use Path.iterdir)
# -----------------------------
def discover_data_files(data_dir: Path) -> Tuple[Tuple[str, ...], Optional[str]]:
    """
    Returns:
      - csv_paths: tuple of CSV file paths (í™˜ê²½ ë°ì´í„° í›„ë³´)
      - xlsx_path: one XLSX path (ìƒìœ¡ ê²°ê³¼ í›„ë³´), or None
    Rules:
      - Use Path.iterdir()
      - Unicode normalize checks (NFC/NFD) for selecting best XLSX if multiple exist
    """
    if not data_dir.exists() or not data_dir.is_dir():
        return tuple(), None

    csv_paths: List[str] = []
    xlsx_candidates: List[Path] = []

    for p in data_dir.iterdir():
        if not p.is_file():
            continue
        suf = p.suffix.lower()
        if suf == ".csv":
            csv_paths.append(str(p))
        elif suf == ".xlsx":
            xlsx_candidates.append(p)

    chosen_xlsx: Optional[Path] = None
    if len(xlsx_candidates) == 1:
        chosen_xlsx = xlsx_candidates[0]
    elif len(xlsx_candidates) > 1:
        # Prefer a file whose name contains 'ìƒìœ¡' or 'ê²°ê³¼' (NFC/NFD-safe), else take the first.
        preferred: List[Path] = []
        for p in xlsx_candidates:
            name = p.name
            if _contains_norm(name, "ìƒìœ¡") or _contains_norm(name, "ê²°ê³¼"):
                preferred.append(p)
        chosen_xlsx = preferred[0] if len(preferred) > 0 else xlsx_candidates[0]

    return tuple(csv_paths), (str(chosen_xlsx) if chosen_xlsx is not None else None)


# -----------------------------
# Robust readers
# -----------------------------
def _read_csv_safely(path: Path) -> pd.DataFrame:
    encodings = ["utf-8-sig", "utf-8", "cp949", "euc-kr"]
    last_err: Optional[Exception] = None
    for enc in encodings:
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception as e:
            last_err = e
    raise RuntimeError("CSV ì½ê¸° ì‹¤íŒ¨: {}".format(path.name)) from last_err


def _standardize_env_columns(df: pd.DataFrame) -> pd.DataFrame:
    cols = [str(c).strip().lower() for c in df.columns]
    df = df.copy()
    df.columns = cols
    missing = [c for c in ENV_REQUIRED_COLS if c not in df.columns]
    if len(missing) > 0:
        raise ValueError("í™˜ê²½ CSV í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {}".format(", ".join(missing)))
    return df


def _find_col_by_keywords(cols: Iterable[str], keywords: List[str]) -> Optional[str]:
    for c in cols:
        ok = True
        for k in keywords:
            if k not in c:
                ok = False
                break
        if ok:
            return c
    return None


def _standardize_growth_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ëª©í‘œ ë‚´ë¶€ ì»¬ëŸ¼:
      - ê°œì²´ë²ˆí˜¸
      - ì ìˆ˜(ì¥)
      - ì§€ìƒë¶€ ê¸¸ì´(mm)
      - ì§€í•˜ë¶€ê¸¸ì´(mm)
      - ìƒì¤‘ëŸ‰(g)
    ì‹œíŠ¸ë§ˆë‹¤ ê³µë°±/ì•½ê°„ì˜ í‘œê¸° ì°¨ì´ë¥¼ ëŒ€ë¹„í•´ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­.
    """
    df2 = df.copy()
    df2.columns = [str(c).strip() for c in df2.columns]
    cols = list(df2.columns)

    # Try exact first, then keyword match
    need = {
        "ê°œì²´ë²ˆí˜¸": ["ê°œì²´", "ë²ˆí˜¸"],
        "ì ìˆ˜(ì¥)": ["ì", "ìˆ˜"],
        "ì§€ìƒë¶€ ê¸¸ì´(mm)": ["ì§€ìƒë¶€", "ê¸¸ì´"],
        "ì§€í•˜ë¶€ê¸¸ì´(mm)": ["ì§€í•˜ë¶€", "ê¸¸ì´"],
        "ìƒì¤‘ëŸ‰(g)": ["ìƒ", "ì¤‘ëŸ‰"],
    }

    rename_map: Dict[str, str] = {}

    for target, keys in need.items():
        if target in cols:
            continue
        found = _find_col_by_keywords(cols, keys)
        if found is not None:
            rename_map[found] = target

    if len(rename_map) > 0:
        df2 = df2.rename(columns=rename_map)

    missing = [t for t in need.keys() if t not in df2.columns]
    if len(missing) > 0:
        raise ValueError("ìƒìœ¡ ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {}".format(", ".join(missing)))

    return df2


# -----------------------------
# Cached loaders
# -----------------------------
@st.cache_data(show_spinner=False)
def load_environment_data(csv_paths: Tuple[str, ...]) -> pd.DataFrame:
    frames: List[pd.DataFrame] = []
    for p_str in csv_paths:
        p = Path(p_str)
        df = _read_csv_safely(p)
        df = _standardize_env_columns(df)

        # í•™êµëª…: íŒŒì¼ëª…ì—ì„œ '_' ì•ë¶€ë¶„ì„ ì‚¬ìš© (íŒŒì¼ëª… í•˜ë“œì½”ë”© X)
        stem = p.stem
        parts = stem.split("_")
        school_raw = parts[0] if len(parts) > 0 else stem
        school_nfc = unicodedata.normalize("NFC", school_raw)

        df["í•™êµ"] = school_nfc

        # time parse
        df["time"] = pd.to_datetime(df["time"], errors="coerce")

        for c in ["temperature", "humidity", "ph", "ec"]:
            df[c] = pd.to_numeric(df[c], errors="coerce")

        df = df.dropna(subset=["time"])
        frames.append(df)

    if len(frames) == 0:
        return pd.DataFrame()

    out = pd.concat(frames, ignore_index=True)
    out = out.sort_values(["í•™êµ", "time"])
    return out


@st.cache_data(show_spinner=False)
def load_growth_data(xlsx_path: str) -> pd.DataFrame:
    p = Path(xlsx_path)
    if not p.exists():
        return pd.DataFrame()

    xls = pd.ExcelFile(p, engine="openpyxl")
    sheets = list(xls.sheet_names)  # ì‹œíŠ¸ëª… í•˜ë“œì½”ë”© ê¸ˆì§€

    frames: List[pd.DataFrame] = []
    for sh in sheets:
        df = pd.read_excel(xls, sheet_name=sh, engine="openpyxl")
        df = _standardize_growth_columns(df)

        school_nfc = unicodedata.normalize("NFC", str(sh).strip())
        df["í•™êµ"] = school_nfc

        # numeric
        for c in ["ì ìˆ˜(ì¥)", "ì§€ìƒë¶€ ê¸¸ì´(mm)", "ì§€í•˜ë¶€ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)"]:
            df[c] = pd.to_numeric(df[c], errors="coerce")

        frames.append(df)

    if len(frames) == 0:
        return pd.DataFrame()

    out = pd.concat(frames, ignore_index=True)

    # EC ëª©í‘œ ë¶™ì´ê¸° (í•™êµëª… NFC/NFD ì•ˆì „ ë¹„êµ)
    out["EC ëª©í‘œ"] = out["í•™êµ"].apply(lambda s: _lookup_by_norm_key(EC_TARGET_BY_SCHOOL, s))
    return out


# -----------------------------
# Download helpers (BytesIO)
# -----------------------------
def dataframe_to_csv_bytes(df: pd.DataFrame) -> bytes:
    # Excel í˜¸í™˜ì„ ìœ„í•´ utf-8-sig
    return df.to_csv(index=False).encode("utf-8-sig")


def dataframe_to_xlsx_bytes_by_school(df: pd.DataFrame) -> io.BytesIO:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        if "í•™êµ" in df.columns and df["í•™êµ"].nunique() > 1:
            for school, sdf in df.groupby("í•™êµ", dropna=False):
                sheet_name = str(school)[:31] if pd.notna(school) else "Unknown"
                sdf.to_excel(writer, index=False, sheet_name=sheet_name)
        else:
            sheet_name = "ë°ì´í„°"
            if "í•™êµ" in df.columns and df["í•™êµ"].nunique() == 1:
                sheet_name = str(df["í•™êµ"].iloc[0])[:31]
            df.to_excel(writer, index=False, sheet_name=sheet_name)

    buffer.seek(0)
    return buffer


# -----------------------------
# Compute summaries
# -----------------------------
def env_means_by_school(env_df: pd.DataFrame) -> pd.DataFrame:
    if env_df.empty:
        return pd.DataFrame()
    g = env_df.groupby("í•™êµ", as_index=False).agg(
        temperature=("temperature", "mean"),
        humidity=("humidity", "mean"),
        ph=("ph", "mean"),
        ec=("ec", "mean"),
        n=("ec", "size"),
    )
    return g


def growth_means_by_ec(growth_df: pd.DataFrame) -> pd.DataFrame:
    if growth_df.empty:
        return pd.DataFrame()
    g = growth_df.groupby("EC ëª©í‘œ", as_index=False).agg(
        mean_weight=("ìƒì¤‘ëŸ‰(g)", "mean"),
        mean_leaves=("ì ìˆ˜(ì¥)", "mean"),
        mean_shoot=("ì§€ìƒë¶€ ê¸¸ì´(mm)", "mean"),
        count=("ìƒì¤‘ëŸ‰(g)", "count"),
    )
    g = g.sort_values("EC ëª©í‘œ")
    return g


def best_ec_from_growth(growth_df: pd.DataFrame) -> Optional[float]:
    g = growth_means_by_ec(growth_df)
    if g.empty or g["mean_weight"].dropna().empty:
        return None
    best_row = g.loc[g["mean_weight"].idxmax()]
    val = best_row["EC ëª©í‘œ"]
    return float(val) if pd.notna(val) else None


# -----------------------------
# Load data
# -----------------------------
APP_DIR = Path(__file__).resolve().parent
DATA_DIR = APP_DIR / "data"

with st.spinner("ë°ì´í„° íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    csv_paths, xlsx_path = discover_data_files(DATA_DIR)

if len(csv_paths) == 0:
    st.error("data/ í´ë”ì—ì„œ í™˜ê²½ ë°ì´í„° CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í™•ì¥ì .csv)")
    st.stop()

if xlsx_path is None:
    st.error("data/ í´ë”ì—ì„œ ìƒìœ¡ ê²°ê³¼ XLSX íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í™•ì¥ì .xlsx)")
    st.stop()

try:
    with st.spinner("í™˜ê²½ ë°ì´í„°ë¥¼ ì½ëŠ” ì¤‘..."):
        env_df = load_environment_data(csv_paths)
    with st.spinner("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°ë¥¼ ì½ëŠ” ì¤‘..."):
        growth_df = load_growth_data(xlsx_path)
except Exception as e:
    st.error("ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {}".format(e))
    st.stop()

if env_df.empty:
    st.error("í™˜ê²½ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. CSV ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

if growth_df.empty:
    st.error("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. XLSX/ì‹œíŠ¸ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# í•™êµ ëª©ë¡(í™˜ê²½+ìƒìœ¡ í•©ì§‘í•©)
schools_env = sorted(list({unicodedata.normalize("NFC", s) for s in env_df["í•™êµ"].dropna().unique()}))
schools_growth = sorted(list({unicodedata.normalize("NFC", s) for s in growth_df["í•™êµ"].dropna().unique()}))
schools_all = sorted(list(set(schools_env).union(set(schools_growth))))

# Sidebar
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬")

selected_school = st.sidebar.selectbox(
    "í•™êµ ì„ íƒ",
    options=["ì „ì²´"] + schools_all,
    index=0,
)

# Filtered views for KPI / raw tables
if selected_school == "ì „ì²´":
    env_scope = env_df.copy()
    growth_scope = growth_df.copy()
else:
    env_scope = env_df[env_df["í•™êµ"].apply(lambda x: _norm_eq(str(x), selected_school))].copy()
    growth_scope = growth_df[growth_df["í•™êµ"].apply(lambda x: _norm_eq(str(x), selected_school))].copy()


# -----------------------------
# Tabs
# -----------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ“– ì‹¤í—˜ ê°œìš”", "ğŸŒ¡ï¸ í™˜ê²½ ë°ì´í„°", "ğŸ“Š ìƒìœ¡ ê²°ê³¼"])


# -----------------------------
# Tab 1: Overview
# -----------------------------
with tab1:
    st.subheader("ì—°êµ¬ ë°°ê²½ ë° ëª©ì ")
    st.markdown(
        """
- ê·¹ì§€ì‹ë¬¼(ì €ì˜¨Â·ì €ê´‘ í™˜ê²½ ì ì‘ ì‹ë¬¼)ì˜ ì•ˆì •ì ì¸ ìƒì¥ì„ ìœ„í•´ **ì–‘ì•¡ì˜ EC(ì „ê¸°ì „ë„ë„) ë†ë„ ìµœì í™”**ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.
- ë³¸ ì—°êµ¬ëŠ” 4ê°œ í•™êµê°€ ì„œë¡œ ë‹¤ë¥¸ EC ì¡°ê±´(1.0 / 2.0 / 4.0 / 8.0)ì—ì„œ ì¬ë°°í•˜ë©°,
  **í™˜ê²½(ì˜¨ë„Â·ìŠµë„Â·pHÂ·EC)** ë° **ìƒìœ¡ ê²°ê³¼(ìƒì¤‘ëŸ‰Â·ì ìˆ˜Â·ê¸¸ì´)**ë¥¼ ë¹„êµí•˜ì—¬ **ìµœì  EC**ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
"""
    )

    # í•™êµë³„ EC ì¡°ê±´ í‘œ
    counts_by_school = (
        growth_df.groupby("í•™êµ", as_index=False)
        .agg(ê°œì²´ìˆ˜=("ìƒì¤‘ëŸ‰(g)", "count"))
        .sort_values("í•™êµ")
    )
    table_rows: List[Dict[str, object]] = []
    for _, r in counts_by_school.iterrows():
        sch = str(r["í•™êµ"])
        ec_t = _lookup_by_norm_key(EC_TARGET_BY_SCHOOL, sch)
        color = "Gray"
        for k, v in SCHOOL_COLOR.items():
            if _norm_eq(k, sch):
                color = v
                break

        table_rows.append(
            {
                "í•™êµëª…": sch,
                "EC ëª©í‘œ": ec_t,
                "ê°œì²´ìˆ˜": int(r["ê°œì²´ìˆ˜"]),
                "ìƒ‰ìƒ": color,
            }
        )
    cond_df = pd.DataFrame(table_rows)

    st.markdown("#### í•™êµë³„ EC ì¡°ê±´")
    st.dataframe(cond_df, use_container_width=True, hide_index=True)

    # KPI cards
    total_n = int(growth_scope["ìƒì¤‘ëŸ‰(g)"].count()) if not growth_scope.empty else 0
    avg_temp = float(env_scope["temperature"].mean()) if not env_scope.empty else float("nan")
    avg_hum = float(env_scope["humidity"].mean()) if not env_scope.empty else float("nan")
    best_ec = best_ec_from_growth(growth_df)  # ìµœì  ECëŠ” ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë„ì¶œ

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ê°œì²´ìˆ˜", "{}".format(total_n))
    c2.metric("í‰ê·  ì˜¨ë„(Â°C)", "-" if pd.isna(avg_temp) else "{:.2f}".format(avg_temp))
    c3.metric("í‰ê·  ìŠµë„(%)", "-" if pd.isna(avg_hum) else "{:.2f}".format(avg_hum))
    c4.metric("ìµœì  EC(ì „ì²´ ê¸°ì¤€)", "-" if best_ec is None else "{:.1f}".format(best_ec))

    # ì•ˆë‚´
    if selected_school != "ì „ì²´":
        st.caption("í˜„ì¬ ì„ íƒ: {}  |  ìµœì  ECëŠ” ì „ì²´(4ê°œêµ) ìƒìœ¡ ê²°ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚°ì¶œí•©ë‹ˆë‹¤.".format(selected_school))


# -----------------------------
# Tab 2: Environment
# -----------------------------
with tab2:
    st.subheader("í•™êµë³„ í™˜ê²½ í‰ê·  ë¹„êµ")

    env_mean = env_means_by_school(env_df)
    if env_mean.empty:
        st.error("í™˜ê²½ í‰ê· ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°/ì»¬ëŸ¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # ì •ë ¬ ê¸°ì¤€: schools_all ìˆœì„œ ìœ ì§€
    env_mean["í•™êµ_sort"] = env_mean["í•™êµ"].apply(lambda s: schools_all.index(s) if s in schools_all else 9999)
    env_mean = env_mean.sort_values("í•™êµ_sort").drop(columns=["í•™êµ_sort"])

    schools_x = env_mean["í•™êµ"].tolist()
    temp_y = env_mean["temperature"].tolist()
    hum_y = env_mean["humidity"].tolist()
    ph_y = env_mean["ph"].tolist()
    ec_measured_y = env_mean["ec"].tolist()

    # target EC list aligned
    ec_target_y: List[Optional[float]] = []
    for sch in schools_x:
        ec_target_y.append(_lookup_by_norm_key(EC_TARGET_BY_SCHOOL, sch))

    fig_env = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ëª©í‘œ EC vs ì‹¤ì¸¡ EC(í‰ê· )"),
        horizontal_spacing=0.12,
        vertical_spacing=0.15,
    )

    fig_env.add_trace(go.Bar(x=schools_x, y=temp_y, name="í‰ê·  ì˜¨ë„"), row=1, col=1)
    fig_env.add_trace(go.Bar(x=schools_x, y=hum_y, name="í‰ê·  ìŠµë„"), row=1, col=2)
    fig_env.add_trace(go.Bar(x=schools_x, y=ph_y, name="í‰ê·  pH"), row=2, col=1)

    fig_env.add_trace(go.Bar(x=schools_x, y=ec_target_y, name="ëª©í‘œ EC", offsetgroup=0), row=2, col=2)
    fig_env.add_trace(go.Bar(x=schools_x, y=ec_measured_y, name="ì‹¤ì¸¡ EC(í‰ê· )", offsetgroup=1), row=2, col=2)

    fig_env.update_layout(
        height=700,
        barmode="group",
        font=dict(family=PLOTLY_FONT_FAMILY),
        legend=dict(orientation="h", yanchor="bottom", y=-0.15, xanchor="left", x=0),
        margin=dict(l=30, r=30, t=60, b=80),
        template="plotly_white",
    )

    st.plotly_chart(fig_env, use_container_width=True)

    st.markdown("---")
    st.subheader("ì„ íƒí•œ í•™êµ ì‹œê³„ì—´")

    # ì „ì²´ ì„ íƒì¼ ë•ŒëŠ” íƒ­ ë‚´ë¶€ì—ì„œ ì‹œê³„ì—´ í•™êµë¥¼ ê³ ë¥¼ ìˆ˜ ìˆê²Œ ì œê³µ
    if selected_school == "ì „ì²´":
        ts_school = st.selectbox(
            "ì‹œê³„ì—´ë¡œ ë³¼ í•™êµ ì„ íƒ",
            options=schools_all,
            index=0 if len(schools_all) == 0 else 0,
            key="ts_school_select",
        )
    else:
        ts_school = selected_school

    env_ts = env_df[env_df["í•™êµ"].apply(lambda x: _norm_eq(str(x), ts_school))].copy()
    if env_ts.empty:
        st.error("ì„ íƒí•œ í•™êµ({})ì˜ í™˜ê²½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.".format(ts_school))
    else:
        env_ts = env_ts.sort_values("time")

        fig_t = px.line(
            env_ts,
            x="time",
            y="temperature",
            title="ì˜¨ë„ ë³€í™”",
            labels={"time": "ì‹œê°„", "temperature": "ì˜¨ë„(Â°C)"},
        )
        fig_t.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), template="plotly_white")
        st.plotly_chart(fig_t, use_container_width=True)

        fig_h = px.line(
            env_ts,
            x="time",
            y="humidity",
            title="ìŠµë„ ë³€í™”",
            labels={"time": "ì‹œê°„", "humidity": "ìŠµë„(%)"},
        )
        fig_h.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), template="plotly_white")
        st.plotly_chart(fig_h, use_container_width=True)

        fig_ec = px.line(
            env_ts,
            x="time",
            y="ec",
            title="EC ë³€í™” (ëª©í‘œ EC ìˆ˜í‰ì„  í¬í•¨)",
            labels={"time": "ì‹œê°„", "ec": "EC"},
        )

        target_ec = _lookup_by_norm_key(EC_TARGET_BY_SCHOOL, ts_school)
        if target_ec is not None and pd.notna(target_ec):
            fig_ec.add_hline(
                y=float(target_ec),
                line_dash="dash",
                annotation_text="ëª©í‘œ EC {}".format(target_ec),
                annotation_position="top left",
            )

        fig_ec.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), template="plotly_white")
        st.plotly_chart(fig_ec, use_container_width=True)

        with st.expander("í™˜ê²½ ë°ì´í„° ì›ë³¸ í…Œì´ë¸” / CSV ë‹¤ìš´ë¡œë“œ"):
            st.dataframe(env_ts, use_container_width=True, hide_index=True)

            csv_bytes = dataframe_to_csv_bytes(env_ts)
            file_name = "í™˜ê²½ë°ì´í„°_{}.csv".format(ts_school)
            st.download_button(
                label="CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_bytes,
                file_name=file_name,
                mime="text/csv",
            )


# -----------------------------
# Tab 3: Growth results
# -----------------------------
with tab3:
    st.subheader("ğŸ¥‡ í•µì‹¬ ê²°ê³¼")

    ec_summary = growth_means_by_ec(growth_df)
    if ec_summary.empty:
        st.error("ECë³„ ìƒìœ¡ ìš”ì•½ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒìœ¡ ë°ì´í„°/ì»¬ëŸ¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    best_ec_val = best_ec_from_growth(growth_df)
    best_weight = None
    if best_ec_val is not None:
        row = ec_summary[ec_summary["EC ëª©í‘œ"] == best_ec_val]
        if not row.empty:
            best_weight = float(row["mean_weight"].iloc[0]) if pd.notna(row["mean_weight"].iloc[0]) else None

    colA, colB = st.columns([1, 2])
    with colA:
        if best_ec_val is None:
            st.metric("ìµœì  EC", "-")
        else:
            label = "ìµœì  EC"
            if abs(best_ec_val - 2.0) < 1e-9:
                label = "ìµœì  EC (í•˜ëŠ˜ê³ , EC 2.0)"
            st.metric(label, "{:.1f}".format(best_ec_val), delta="í‰ê·  ìƒì¤‘ëŸ‰ {:.3f} g".format(best_weight) if best_weight is not None else None)

    with colB:
        show_df = ec_summary.copy()
        show_df["EC ëª©í‘œ"] = show_df["EC ëª©í‘œ"].map(lambda x: "-" if pd.isna(x) else "{:.1f}".format(float(x)))
        show_df["í‰ê·  ìƒì¤‘ëŸ‰(g)"] = show_df["mean_weight"].map(lambda x: "-" if pd.isna(x) else "{:.3f}".format(float(x)))
        show_df["í‰ê·  ì ìˆ˜"] = show_df["mean_leaves"].map(lambda x: "-" if pd.isna(x) else "{:.2f}".format(float(x)))
        show_df["í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)"] = show_df["mean_shoot"].map(lambda x: "-" if pd.isna(x) else "{:.2f}".format(float(x)))
        show_df["ê°œì²´ìˆ˜"] = show_df["count"].astype(int)
        show_df = show_df[["EC ëª©í‘œ", "í‰ê·  ìƒì¤‘ëŸ‰(g)", "í‰ê·  ì ìˆ˜", "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)", "ê°œì²´ìˆ˜"]]
        st.dataframe(show_df, use_container_width=True, hide_index=True)

    st.markdown("---")
    st.subheader("ECë³„ ìƒìœ¡ ë¹„êµ (2x2)")

    ec_x = ec_summary["EC ëª©í‘œ"].tolist()
    w_y = ec_summary["mean_weight"].tolist()
    l_y = ec_summary["mean_leaves"].tolist()
    s_y = ec_summary["mean_shoot"].tolist()
    c_y = ec_summary["count"].tolist()

    fig_g = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("í‰ê·  ìƒì¤‘ëŸ‰(g) â­", "í‰ê·  ì ìˆ˜", "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)", "ê°œì²´ìˆ˜ ë¹„êµ"),
        horizontal_spacing=0.12,
        vertical_spacing=0.15,
    )

    fig_g.add_trace(go.Bar(x=ec_x, y=w_y, name="í‰ê·  ìƒì¤‘ëŸ‰"), row=1, col=1)
    fig_g.add_trace(go.Bar(x=ec_x, y=l_y, name="í‰ê·  ì ìˆ˜"), row=1, col=2)
    fig_g.add_trace(go.Bar(x=ec_x, y=s_y, name="í‰ê·  ì§€ìƒë¶€ ê¸¸ì´"), row=2, col=1)
    fig_g.add_trace(go.Bar(x=ec_x, y=c_y, name="ê°œì²´ìˆ˜"), row=2, col=2)

    # ìµœëŒ“ê°’(í‰ê·  ìƒì¤‘ëŸ‰) í‘œì‹œ
    if ec_summary["mean_weight"].dropna().size > 0:
        idx = ec_summary["mean_weight"].idxmax()
        x_best = ec_summary.loc[idx, "EC ëª©í‘œ"]
        y_best = ec_summary.loc[idx, "mean_weight"]
        fig_g.add_trace(
            go.Scatter(
                x=[x_best],
                y=[y_best],
                mode="markers+text",
                text=["ìµœëŒ“ê°’"],
                textposition="top center",
                name="ìµœëŒ“ê°’(ìƒì¤‘ëŸ‰)",
            ),
            row=1,
            col=1,
        )

    fig_g.update_layout(
        height=720,
        barmode="group",
        font=dict(family=PLOTLY_FONT_FAMILY),
        legend=dict(orientation="h", yanchor="bottom", y=-0.15, xanchor="left", x=0),
        margin=dict(l=30, r=30, t=60, b=80),
        template="plotly_white",
    )
    st.plotly_chart(fig_g, use_container_width=True)

    st.markdown("---")
    st.subheader("í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬")

    # ë¶„í¬ëŠ” í•™êµ ë¹„êµ ëª©ì ì´ë¯€ë¡œ ì „ì²´ ê¸°ì¤€ í‘œì‹œ
    fig_dist = px.box(
        growth_df,
        x="í•™êµ",
        y="ìƒì¤‘ëŸ‰(g)",
        points="outliers",
        title="í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬ (Box Plot)",
        labels={"í•™êµ": "í•™êµ", "ìƒì¤‘ëŸ‰(g)": "ìƒì¤‘ëŸ‰(g)"},
    )
    fig_dist.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), template="plotly_white")
    st.plotly_chart(fig_dist, use_container_width=True)

    st.markdown("---")
    st.subheader("ìƒê´€ê´€ê³„ ë¶„ì„")

    fig_sc1 = px.scatter(
        growth_df if selected_school == "ì „ì²´" else growth_scope,
        x="ì ìˆ˜(ì¥)",
        y="ìƒì¤‘ëŸ‰(g)",
        color="í•™êµ" if selected_school == "ì „ì²´" else None,
        title="ì ìˆ˜ vs ìƒì¤‘ëŸ‰",
        labels={"ì ìˆ˜(ì¥)": "ì ìˆ˜(ì¥)", "ìƒì¤‘ëŸ‰(g)": "ìƒì¤‘ëŸ‰(g)"},
    )
    fig_sc1.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), template="plotly_white")
    st.plotly_chart(fig_sc1, use_container_width=True)

    fig_sc2 = px.scatter(
        growth_df if selected_school == "ì „ì²´" else growth_scope,
        x="ì§€ìƒë¶€ ê¸¸ì´(mm)",
        y="ìƒì¤‘ëŸ‰(g)",
        color="í•™êµ" if selected_school == "ì „ì²´" else None,
        title="ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰",
        labels={"ì§€ìƒë¶€ ê¸¸ì´(mm)": "ì§€ìƒë¶€ ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)": "ìƒì¤‘ëŸ‰(g)"},
    )
    fig_sc2.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), template="plotly_white")
    st.plotly_chart(fig_sc2, use_container_width=True)

    with st.expander("í•™êµë³„ ìƒìœ¡ ë°ì´í„° ì›ë³¸ / XLSX ë‹¤ìš´ë¡œë“œ"):
        if selected_school == "ì „ì²´":
            st.dataframe(growth_df, use_container_width=True, hide_index=True)
            download_df = growth_df
            file_tag = "ì „ì²´"
        else:
            st.dataframe(growth_scope, use_container_width=True, hide_index=True)
            download_df = growth_scope
            file_tag = selected_school

        buffer = dataframe_to_xlsx_bytes_by_school(download_df)
        st.download_button(
            label="XLSX ë‹¤ìš´ë¡œë“œ",
            data=buffer,
            file_name="ìƒìœ¡ê²°ê³¼_{}.xlsx".format(file_tag),
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
